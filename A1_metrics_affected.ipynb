{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with marginal metrics\n",
    "\n",
    "While pair-wise and dataset-wide metrics are sure to be affected by the disjoint generative models (DGMs) workflow, it was initially assumed that marginal metrics were unaffected beyond being aggregated in proportion to the size of the partition. This notebook explores the behavior of marginal metrics in the context of DGMs, and shows that the joining operation makes them be affected.\n",
    "\n",
    "The following metrics are considered:\n",
    "\n",
    "- Hellinger distance\n",
    "- Kolglomorov-Smirnov/TVD statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame\n",
    "from typing import List, Dict\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from syntheval import SynthEval\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from disjoint_generative_model import DisjointGenerativeModels\n",
    "from disjoint_generative_model.utils.joining_validator import JoiningValidator\n",
    "from disjoint_generative_model.utils.joining_strategies import UsingJoiningValidator\n",
    "from disjoint_generative_model.utils.dataset_manager import random_split_columns\n",
    "from disjoint_generative_model.utils.generative_model_adapters import generate_synthetic_data\n",
    "\n",
    "### Metrics\n",
    "metrics = {\n",
    "    \"h_dist\"    : {},\n",
    "    \"ks_test\"   : {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "df_train = pd.read_csv('experiments/datasets/hepatitis_train.csv')\n",
    "df_test = pd.read_csv('experiments/datasets/hepatitis_test.csv')\n",
    "\n",
    "label = 'b_class'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find out more at https://www.synthpop.org.uk/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable(s): WBC, RBC, Plat, RNA.Base, RNA.4, RNA.12, RNA.EOT, RNA.EF have been changed for synthesis from character to factor.\n",
      "\n",
      "Variable(s): Gender, Fever, Nausea.Vomting, Headache, Diarrhea, Fatigue...generalized.bone.ache, Jaundice, Epigastric.pain, b_class numeric but with only 3 or fewer distinct values turned into factor(s) for synthesis.\n",
      "\n",
      "Synthetic data exported as csv file(s).\n",
      "Information on synthetic data written to\n",
      "  /home/lautrup/repositories/disjoint-synthetic-data-generation/synthesis_info_synthpop_temp_0_synthpop.txt \n",
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT Baseline histological Grading\n",
      "Adding attribute ALT 24\n",
      "Adding attribute ALT 4\n",
      "Adding attribute ALT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7f18da9a0940>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding attribute ALT 12\n",
      "Adding attribute AST 1\n",
      "Adding attribute Age\n"
     ]
    }
   ],
   "source": [
    "df_cart = generate_synthetic_data(df_train, 'synthpop')\n",
    "\n",
    "df_bn = generate_synthetic_data(df_train, 'datasynthesizer')\n",
    "\n",
    "df_ctgan = generate_synthetic_data(df_train, 'ctgan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT Fever\n",
      "Adding attribute ALT 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find out more at https://www.synthpop.org.uk/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable(s): Plat, RNA.Base, RBC, RNA.EF, WBC, Headache, Nausea.Vomting numeric but with only 3 or fewer distinct values turned into factor(s) for synthesis.\n",
      "\n",
      "Adding attribute ALT 4\n",
      "Synthetic data exported as csv file(s).\n",
      "Information on synthetic data written to\n",
      "  /home/lautrup/repositories/disjoint-synthetic-data-generation/synthesis_info_synthpop_temp_0_synthpop.txt \n",
      "Adding attribute AST 1\n",
      "Adding attribute HGB\n",
      "Adding attribute Fatigue & generalized bone ache\n",
      "Adding attribute Jaundice\n",
      "Adding attribute Diarrhea\n",
      "Adding attribute Epigastric pain\n",
      "Adding attribute Gender\n",
      "Adding attribute b_class\n",
      "Adding attribute RNA 12\n",
      "Adding attribute RNA EOT\n",
      "Adding attribute RNA 4\n",
      "========================== BN constructed ==========================\n",
      "Final size of synthetic data: 5090\n"
     ]
    }
   ],
   "source": [
    "### DGM with Random Forest\n",
    "Rf = RandomForestClassifier(n_estimators=100)\n",
    "JS = UsingJoiningValidator(JoiningValidator(Rf, verbose=False), patience=5)\n",
    "\n",
    "prepared_splits = random_split_columns(df_train, {'split1': 1, 'split2': 1})\n",
    "\n",
    "dgms = DisjointGenerativeModels(df_train,['synthpop', 'datasynthesizer'], \n",
    "                                prepared_splits= prepared_splits, \n",
    "                                joining_strategy=JS)\n",
    "dgms.join_multiplier = 8    # to ensure high enough resolution\n",
    "\n",
    "df_dgms = dgms.fit_generate()[:len(df_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    'sp' : df_cart,\n",
    "    'ds' : df_bn,\n",
    "    'gan' : df_ctgan,\n",
    "    'dgms' : df_dgms\n",
    "}\n",
    "\n",
    "SE = SynthEval(df_train, df_test, verbose=False)\n",
    "res, _ = SE.benchmark(dfs, analysis_target_var=label,**metrics, rank_strategy='summation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">avg_h_dist</th>\n",
       "      <th colspan=\"2\" halign=\"left\">ks_tvd_stat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">frac_ks_sigs</th>\n",
       "      <th>rank</th>\n",
       "      <th>u_rank</th>\n",
       "      <th>p_rank</th>\n",
       "      <th>f_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>error</th>\n",
       "      <th>value</th>\n",
       "      <th>error</th>\n",
       "      <th>value</th>\n",
       "      <th>error</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sp</th>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.980356</td>\n",
       "      <td>2.980356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.020845</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.829955</td>\n",
       "      <td>2.829955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gan</th>\n",
       "      <td>0.015594</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.05873</td>\n",
       "      <td>0.008581</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.373952</td>\n",
       "      <td>2.373952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dgms</th>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.704992</td>\n",
       "      <td>2.704992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        avg_h_dist           ks_tvd_stat           frac_ks_sigs        \\\n",
       "             value     error       value     error        value error   \n",
       "dataset                                                                 \n",
       "sp        0.005138  0.001426    0.014506  0.002161          0.0   NaN   \n",
       "ds        0.011269  0.003119    0.020845  0.002543     0.137931   NaN   \n",
       "gan       0.015594  0.003316     0.05873  0.008581     0.551724   NaN   \n",
       "dgms      0.015053   0.00335    0.038575  0.004713     0.241379   NaN   \n",
       "\n",
       "             rank    u_rank p_rank f_rank  \n",
       "                                           \n",
       "dataset                                    \n",
       "sp       2.980356  2.980356    0.0    0.0  \n",
       "ds       2.829955  2.829955    0.0    0.0  \n",
       "gan      2.373952  2.373952    0.0    0.0  \n",
       "dgms     2.704992  2.704992    0.0    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008097793103448275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.3007356321839083"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = (0.005138*len(prepared_splits['split1'])+0.011269*len(prepared_splits['split2']))/len(df_train.columns)\n",
    "print(exp)\n",
    "t = abs(0.015-exp)/0.003\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appers that the both metrics are affected by the DGMs workflow. This is likely due to the joining operation not being completely random, thus affecting which records are carried to the joined dataset.\n",
    "\n",
    "To check that this is the case, we will run one more experiment using the concatenation joining instead of the joining validator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lautrup/repositories/disjoint-synthetic-data-generation/disjoint_generative_model/utils/dataset_manager.py:35: UserWarning: Split sizes adjusted to {'split1': 15, 'split2': 14}\n",
      "  warnings.warn(f\"Split sizes adjusted to {split_sizes}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Constructing Bayesian Network (BN) ================\n",
      "Adding ROOT Baseline histological Grading\n",
      "Adding attribute ALT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Find out more at https://www.synthpop.org.uk/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable(s): Fever, WBC, RNA.4, RNA.Base, RNA.EF, RNA.12, Jaundice, Gender, Headache, Plat, RBC, Epigastric.pain numeric but with only 3 or fewer distinct values turned into factor(s) for synthesis.\n",
      "\n",
      "Adding attribute ALT 12\n",
      "Synthetic data exported as csv file(s).\n",
      "Information on synthetic data written to\n",
      "  /home/lautrup/repositories/disjoint-synthetic-data-generation/synthesis_info_synthpop_temp_0_synthpop.txt \n",
      "Adding attribute ALT 1\n",
      "Adding attribute AST 1\n",
      "Adding attribute ALT 48\n",
      "Adding attribute ALT 36\n",
      "Adding attribute BMI\n",
      "Adding attribute HGB\n",
      "Adding attribute Fatigue & generalized bone ache\n",
      "Adding attribute Diarrhea\n",
      "Adding attribute Nausea/Vomting\n",
      "Adding attribute b_class\n",
      "Adding attribute RNA EOT\n",
      "========================== BN constructed ==========================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>dim</th>\n",
       "      <th>val</th>\n",
       "      <th>err</th>\n",
       "      <th>n_val</th>\n",
       "      <th>n_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg_h_dist</td>\n",
       "      <td>u</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.993452</td>\n",
       "      <td>0.001403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ks_tvd_stat</td>\n",
       "      <td>u</td>\n",
       "      <td>0.016847</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.983153</td>\n",
       "      <td>0.001765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frac_ks_sigs</td>\n",
       "      <td>u</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         metric dim       val       err     n_val     n_err\n",
       "0    avg_h_dist   u  0.006548  0.001403  0.993452  0.001403\n",
       "1   ks_tvd_stat   u  0.016847  0.001765  0.983153  0.001765\n",
       "2  frac_ks_sigs   u  0.000000       NaN  1.000000       NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DGM with Concatenation\n",
    "prepared_splits = random_split_columns(df_train, {'split1': 1, 'split2': 1})\n",
    "\n",
    "dgms = DisjointGenerativeModels(df_train,['synthpop', 'datasynthesizer'], \n",
    "                                prepared_splits= prepared_splits)\n",
    "\n",
    "df_dgms = dgms.fit_generate()[:len(df_train)]\n",
    "\n",
    "SE = SynthEval(df_train, df_test, verbose=False)\n",
    "SE.evaluate(df_dgms, analysis_target_var=label, **metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008097793103448275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.784137931034482"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = (0.005138*len(prepared_splits['split1'])+0.011269*len(prepared_splits['split2']))/len(df_train.columns)\n",
    "print(exp)\n",
    "t = abs(0.007-exp)/0.0014\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More plausible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
